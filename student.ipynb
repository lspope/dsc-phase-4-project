{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: Leah Pope\n",
    "* Student pace: Full Time\n",
    "* Scheduled project review date/time: 12/17/2020\n",
    "* Instructor name: James Irving\n",
    "* Blog post URL: https://leahspope7.medium.com/comparing-vader-and-text-blob-to-human-sentiment-77068cf7398 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your code here - remember to use markdown cells for comments as well!_\n",
    "\n",
    "Code is located in separate notebooks under the ./notebooks directory. \n",
    "* [Data Cleaning and EDA](./notebooks/data_cleaning_and_eda.ipynb)\n",
    "* [Binary Classifier Modeling](./notebooks/modeling.ipynb)\n",
    "* [Multiclass Classifier Modeling](./notebooks/modeling.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Phase 4 Project - NLP for Classifying Consumer Tweets\n",
    "Prepared and presented by: [Leah Pope](https://www.linkedin.com/in/leahspope/)\n",
    "Presentation: [here](./extras/PhaseFourProject_LeahPope.pdf)\n",
    "Blog: [On Medium](https://leahspope7.medium.com/comparing-vader-and-text-blob-to-human-sentiment-77068cf73982)\n",
    "\n",
    "\n",
    "# Introduction\n",
    "The goal of this project is to build a Natural Language Processing model to analyze sentiment about Apple and Google products. I'll classify a Tweet as negative, positive or neutral based on its content.\n",
    "\n",
    "The Stakeholders for my project are marketing professionals in either company who are interested in learning consumer sentiment. It appears that these tweets were gathered during a session of the South by Southwest film, culture, music, and technology conference. This consumer sentiment would be of interest to the conference marketing professionals and vendor organizers.\n",
    "\n",
    "\n",
    "# Data Description\n",
    "The dataset for the project comes from [CrowdFlower](https://data.world/crowdflower) via [data.world](https://data.world/crowdflower/brands-and-product-emotions). Human raters rated the sentiment in over 9,000 Tweets as positive, negative, or neither.\n",
    "\n",
    "# EDA Questions Explored\n",
    "### Question 1: What is the general breakdown for these Tweets?\n",
    "### Question 2: Are the two brands represented equally in the labeled data?\n",
    "### Question 3: What insights can the data provide for specific brands?\n",
    "#### [Notebook](./notebooks/data_cleaning_and_eda.ipynb)\n",
    "\n",
    "\n",
    "# Corpus EDA Questions Explored\n",
    "### Question 1: What are the most common words in Postitive/Negative/Neutral Tweets?\n",
    "### Question 2: Is there a difference in character count between Postitive/Negative/Neutral Tweets?\n",
    "#### [Notebook](./notebooks/data_cleaning_and_eda.ipynb)\n",
    "\n",
    "# Modeling\n",
    "### Creating binary and multiclass classifiers for Tweets on Apple and Google products.\n",
    "#### [Notebook for Binary Classifiers](./notebooks/modeling.ipynb)\n",
    "#### [Notebook for Multiclass Classifers](./notebooks/modeling2.ipynb)\n",
    "\n",
    "\n",
    "## Conclusions\n",
    "### Binary Classifer - winning model\n",
    "* RandomForest with RandomOverSampling: Weighted F1 Score of __0.87__\n",
    "\n",
    "None of the binary classifiers did a good job with classifying Negative tweets, even with RandomOverSampling. __RandomForest__ and __RandomForest with RandomOverSampling__ had the highest weighted F1 scores of all models I trained.  I'm calling __RandomForest with RandomOverSampling__ the winner as it has a slightly better True Positive rate for correctly identifying Negative Tweets (0.37 vs 0.3). This is still crummy.\n",
    "\n",
    "Here's the breakdown of all Binary Classifier Models:\n",
    "* __MODEL__ - __Weighted F1 Score__\n",
    "* RandomForest - 0.87\n",
    "* RandomForest ROS - 0.87  \n",
    "* Multimonial NB  - 0.82\n",
    "* Multimonial NB ROS - 0.85\n",
    "\n",
    "\n",
    "### Multiclass Classifer - winning model\n",
    "* RandomForest with RandomOverSampling: Weighted F1 Score of __0.68__\n",
    "\n",
    "RandomForest (and RandomForest with RandomOverSampling) had the highest weighted F1 scores of all models I trained. I'm calling RandomForest with RandomOverSampling the winner as it has a slightly better True Positive rate for correctly identifying Negative Tweets (0.29 vs 0.25). I imagine Negative tweets are most interesting to stakeholders. It also has a better True Positive rate for correctly identifying Positive Tweets (0.56 vs 0.48). These numbers are still pretty poor.\n",
    "\n",
    "Here's the breakdown of all Multiclass Classifier Models:\n",
    "* __MODEL__ - __Weighted F1 Score__\n",
    "* RandomForest - 0.68\n",
    "* RandomForest ROS - 0.68\n",
    "* Multimonial NB - 0.60\n",
    "* Multimonial NB ROS - 0.62\n",
    "\n",
    "\n",
    "# Stakeholder Recommendations\n",
    "After analyzing the most common terms/bi-grams in Positive and Negative tweets, I can make the following Stakeholder Recommendations:\n",
    "\n",
    "From the Negative Tweets, we see “iPad design, design headaches, and iphone battery” as common terms. \n",
    "* Recommend to check iPhone battery performance\n",
    "* Revaluate iPad design in light of this Negative sentiment\n",
    "\n",
    "From the Positive Tweets, we see “Apple store, opening temporary, and Google party” as common\n",
    "terms. \n",
    "* Recommend to repeat those two well received events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}